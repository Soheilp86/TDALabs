{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Video Sliding Windows</h1>\n",
    "\n",
    "<p>\n",
    "So far we restricted ourselves to 1D time series, but the idea of recovering periodic dynamics with geometry can just as easily apply to multivariate signals.  In this module, we will examine sliding windows of videos as an exmaple.  Many natural videos also have periodicity, such as this video of a woman doing jumping jacks\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "video = io.open('jumpingjacks.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Video can be decomposed into a 3D array, which has dimensions width x height x time.  To tease out periodicity in geometric form, we will do the exact same thing as with sliding window 1D signal embeddings, but instead of just one sample per time shift, we need to take every pixel in every frame in the time window.  The figure below depicts this\n",
    "</p>\n",
    "\n",
    "<img src = \"VideoStackTime.svg\"><BR><BR>\n",
    "\n",
    "To see this visually in the video next to PCA of the embedding, look at the following video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open('jumpingjackssliding.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>PCA Preprocessing for Efficiency</h2><BR>\n",
    "One issue we have swept under the rug so far is memory consumption and computational efficiency.  Doing a raw sliding window of every pixel of every frame in the video would blow up in memory.  However, even though there are <code>WH</code> pixels in each frame, there are only <code>N</code> frames in the video.  This means that each frame in the video can be represented in an <code>(N-1)</code> dimensional subspace of the pixel space, and the coordinates of this subspace can be used in lieu of the pixels in the sliding window embedding.  This can be done efficiently with a PCA step before the sliding window embedding.  Run the cell below to load code that does PCA efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do all of the imports and setup inline plotting\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import scipy.interpolate\n",
    "\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "from VideoTools import *\n",
    "\n",
    "##Here is the actual PCA code\n",
    "def getPCAVideo(I):\n",
    "    ICov = I.dot(I.T)\n",
    "    [lam, V] = linalg.eigh(ICov)\n",
    "    V = V*np.sqrt(lam[None, :])\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Jumping Jacks Example Live Demo</h2><BR>\n",
    "Let's now load in code that does sliding window embeddings of videos.  The code is very similar to the 1D case, and it has the exact same parameters.  The only difference is that each sliding window lives in a Euclidean space of dimension the number of pixels times <code>dim</code>.  We're also using linear interpolation instead of spline interpolation to keep things fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSlidingWindowVideo(I, dim, Tau, dT):\n",
    "    N = I.shape[0] #Number of frames\n",
    "    P = I.shape[1] #Number of pixels (possibly after PCA)\n",
    "    pix = np.arange(P)\n",
    "    NWindows = int(np.floor((N-dim*Tau)/dT))\n",
    "    X = np.zeros((NWindows, dim*P))\n",
    "    idx = np.arange(N)\n",
    "    for i in range(NWindows):\n",
    "        idxx = dT*i + Tau*np.arange(dim)\n",
    "        start = int(np.floor(idxx[0]))\n",
    "        end = int(np.ceil(idxx[-1]))+2\n",
    "        if end >= I.shape[0]:\n",
    "            X = X[0:i, :]\n",
    "            break\n",
    "        f = scipy.interpolate.interp2d(pix, idx[start:end+1], I[idx[start:end+1], :], kind='linear')\n",
    "        X[i, :] = f(pix, idxx).flatten()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's load in the jumping jacks video and perform PCA to reduce the number of effective pixels.  <BR>\n",
    "<i>Note that loading the video may take a few seconds on the virtual image</i>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in video and do PCA to compress dimension\n",
    "(X, FrameDims) = loadImageIOVideo(\"jumpingjacks.ogg\")\n",
    "X = getPCAVideo(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a sliding window embedding and examine the sliding window embedding using TDA.  As before, you should tweak the parameters of the sliding window embedding and study the effect on the geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given that the period is 30 frames per cycle, choose a dimension and a Tau that capture \n",
    "#this motion in the roundest possible way\n",
    "#Plot persistence diagram and PCA\n",
    "dim = 30\n",
    "Tau = 1\n",
    "dT = 1\n",
    "\n",
    "#Get sliding window video\n",
    "XS = getSlidingWindowVideo(X, dim, Tau, dT)\n",
    "\n",
    "#Mean-center and normalize sliding window\n",
    "XS = XS - np.mean(XS, 1)[:, None]\n",
    "XS = XS/np.sqrt(np.sum(XS**2, 1))[:, None]\n",
    "\n",
    "#Get persistence diagrams\n",
    "dgms = ripser(XS)['dgms']\n",
    "\n",
    "#Do PCA for visualization\n",
    "pca = PCA(n_components = 3)\n",
    "Y = pca.fit_transform(XS)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plot_diagrams(dgms)\n",
    "plt.title(\"1D Persistence Diagram\")\n",
    "\n",
    "c = plt.get_cmap('nipy_spectral')\n",
    "C = c(np.array(np.round(np.linspace(0, 255, Y.shape[0])), dtype=np.int32))\n",
    "C = C[:, 0:3]\n",
    "ax2 = fig.add_subplot(122, projection = '3d')\n",
    "ax2.set_title(\"PCA of Sliding Window Embedding\")\n",
    "ax2.scatter(Y[:, 0], Y[:, 1], Y[:, 2], c=C)\n",
    "ax2.set_aspect('equal', 'datalim')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Periodicities in The KTH Dataset</h1><BR>\n",
    "\n",
    "We will now examine videos from the <a href = \"http://www.nada.kth.se/cvap/actions/\">KTH dataset</a>, which is a repository of black and white videos of human activities.  It consists of 25 subjects performing 6 different actions in each of 4 scenarios.  We will use the algorithms developed in this section to measure and rank the periodicity of the different video clips.\n",
    "\n",
    "<h2>Varying Window Length</h2><BR>\n",
    "For our first experiment, we will be showing some precomputed results of varying the sliding window length, while choosing Tau and dT appropriately to keep the dimension and the number of points, respectively, the same in the sliding window embedding.  As an example, we will apply it to one of the videos of a subject waving his hands back and forth, as shown below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open('KTH/handwaving/person01_handwaving_d1_uncomp.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done some additional preprocessing, including applying a bandpass filter to each PCA pixel to cut down on drift in the video.  Below we show a video varying the window size of the embedding and plotting the persistence diagram, \"self-similarity matrix\" (distance matrix), and PCA of the embedding, as well as an evolving plot of the maximum persistence versus window size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open('Handwaving_Deriv10_Block160_PCA10.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the maximum persistence peaks at around 40 frames, which is the period of each hand wave.  This is what the theory we developed for 1D time series would have predicted as the roundest window.<BR>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quasiperiodicity Quantification in Video</h1><BR>\n",
    "\n",
    "<p>\n",
    "We now examine how this pipeline can be used to detect quasiperiodicity in videos.  As an example, we examine videos from high-speed glottography, or high speed videos (4000 fps) of the left and right vocal folds in the human vocal tract.  When a person has a normal voice, the vocal folds oscillate in a periodic fashion.  On the other hand, if they have certain types of paralysis or near chaotic dynamics, they can exhibit biphonation just as the horse whinnies did.  More info can be found in <a href = \"https://arxiv.org/abs/1704.08382\">this paper</a>.\n",
    "</p>\n",
    "\n",
    "<h2>Healthy Subject</h2>\n",
    "<p>\n",
    "Let's begin by analyzing a video of a healthy person.  In this example and in the following example, we will be computing both persistent H1 and persistent H2, so the code may take a bit longer to run.\n",
    "</p>\n",
    "\n",
    "#### Questions\n",
    "* What can we say about the vocal folds of a healthy subject based on the persistence diagram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open('NormalPeriodicCrop.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, FrameDims) = loadVideo(\"NormalPeriodicCrop.ogg\")\n",
    "X = getPCAVideo(X)\n",
    "dim = 70\n",
    "Tau = 0.5\n",
    "dT = 1\n",
    "derivWin = 10\n",
    "\n",
    "#Take a bandpass filter in time at each pixel to smooth out noise\n",
    "[X, validIdx] = getTimeDerivative(X, derivWin)\n",
    "\n",
    "#Do the sliding window\n",
    "XS = getSlidingWindowVideo(X, dim, Tau, dT)\n",
    "\n",
    "#Mean-center and normalize sliding window\n",
    "XS = XS - np.mean(XS, 1)[:, None]\n",
    "XS = XS/np.sqrt(np.sum(XS**2, 1))[:, None]\n",
    "\n",
    "#Compute and plot persistence diagrams\n",
    "print(\"Computing persistence diagrams...\")\n",
    "dgms = ripser(XS, maxdim=2)['dgms']\n",
    "print(\"Finished computing persistence diagrams\")\n",
    "\n",
    "plt.figure()\n",
    "plot_diagrams(dgms)\n",
    "plt.title(\"Persistence Diagrams$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Subject with Biphonation</h2>\n",
    "<p>\n",
    "Let's now examine a video of someone with a vocal pathology.  This video may still appear periodic, but if you look closely there's a subtle shift going on over time\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open('ClinicalAsymmetry.mp4', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, FrameDims) = loadVideo(\"ClinicalAsymmetry.mp4\")\n",
    "X = getPCAVideo(X)\n",
    "X = X[0:200, :]\n",
    "#'dim':32, 'Tau':0.25, 'dT':0.25, 'derivWin':2\n",
    "dim = 100\n",
    "Tau = 0.25\n",
    "dT = 0.5\n",
    "derivWin = 5\n",
    "\n",
    "#Take a bandpass filter in time at each pixel to smooth out noise\n",
    "[X, validIdx] = getTimeDerivative(X, derivWin)\n",
    "\n",
    "#Do the sliding window\n",
    "XS = getSlidingWindowVideo(X, dim, Tau, dT)\n",
    "print(\"XS.shape = \", XS.shape)\n",
    "\n",
    "#Mean-center and normalize sliding window\n",
    "XS = XS - np.mean(XS, 1)[:, None]\n",
    "XS = XS/np.sqrt(np.sum(XS**2, 1))[:, None]\n",
    "\n",
    "#Compute and plot persistence diagrams\n",
    "print(\"Computing persistence diagrams...\")\n",
    "dgms = ripser(XS, maxdim=2)['dgms']\n",
    "print(\"Finished computing persistence diagrams\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Persistence Diagrams$\")\n",
    "plot_diagrams(dgms)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "* What shape is this?  What does this say about the underlying frequencies involved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Another Subject with Biphonation</h2>\n",
    "<p>\n",
    "Let's now examine another person with a vocal pathology, this time due to mucus that is pushed out of the vocal folds every other oscillation.  This time, we will look at both $\\mathbb{Z} / 2\\mathbb{Z}$ coefficients and $\\mathbb{Z} / 3 \\mathbb{Z}$ coefficients.\n",
    "</p>\n",
    "\n",
    "#### Questions\n",
    "* Can you see any changes between $\\mathbb{Z} / 2\\mathbb{Z}$ coefficients and $\\mathbb{Z} / 3 \\mathbb{Z}$ coefficients?  the What shape is this?  Can you relate this to something we've seen before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = io.open('LTR_ED_MucusBiphonCrop.ogg', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, FrameDims) = loadVideo(\"LTR_ED_MucusBiphonCrop.ogg\")\n",
    "X = getPCAVideo(X)\n",
    "X = X[0:200, :]\n",
    "#'dim':32, 'Tau':0.25, 'dT':0.25, 'derivWin':2\n",
    "dim = 100\n",
    "Tau = 1\n",
    "dT = 0.25\n",
    "derivWin = 5\n",
    "\n",
    "#Take a bandpass filter in time at each pixel to smooth out noise\n",
    "[X, validIdx] = getTimeDerivative(X, derivWin)\n",
    "\n",
    "#Do the sliding window\n",
    "XS = getSlidingWindowVideo(X, dim, Tau, dT)\n",
    "print(\"XS.shape = \", XS.shape)\n",
    "\n",
    "#Mean-center and normalize sliding window\n",
    "XS = XS - np.mean(XS, 1)[:, None]\n",
    "XS = XS/np.sqrt(np.sum(XS**2, 1))[:, None]\n",
    "\n",
    "#Compute and plot persistence diagrams\n",
    "print(\"Computing persistence diagrams...\")\n",
    "dgms2 = ripser(XS, maxdim=2, coeff=2)['dgms']\n",
    "dgms3 = ripser(XS, maxdim=2, coeff=3)['dgms']\n",
    "print(\"Finished computing persistence diagrams\")\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(121)\n",
    "plot_diagrams(dgms2)\n",
    "plt.title(\"Persistence Diagrams $\\mathbb{Z}2$\")\n",
    "plt.subplot(122)\n",
    "plot_diagrams(dgms3)\n",
    "plt.title(\"Persistence Diagrams $\\mathbb{Z}3$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h1>Summary</h1>\n",
    "<ul>\n",
    "<li>Periodicity can be studied on general time series data, including multivariate time series such as video</li>\n",
    "<li>Computational tricks, such as PCA, can be employed to make sliding window videos computationally tractable</li>\n",
    "<li>It is even possible to pick up on quasiperiodicity/biphonation in videos without doing any tracking.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
